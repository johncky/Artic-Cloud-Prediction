---
title: "CVmaster_run"
author: "Kwong Yu Chong, Jiahua Wang"
date: "2022-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
require(tidyverse)
require(kableExtra)
require(patchwork)
require(GGally)
require(corrplot)
require(RColorBrewer)
require(tidymodels)
require(discrim)
require(ranger)
require(xgboost)
set.seed(666)

img1 = read.table("imagem1.txt")
img2 = read.table("imagem2.txt")
img3 = read.table("imagem3.txt")
col_name = c("Y","X","Label","NDAI","SD","CORR","Rad_Df",
             "Rad_Cf","Rad_Bf","Rad_Af","Rad_An")
colnames(img1) = col_name
colnames(img2) = col_name
colnames(img3) = col_name

img1$image = 1
img2$image = 2
img3$image = 3

full_img = rbind(img1, img2, img3)
full_img_no_unlabeled = full_img %>% filter(Label!=0)

block_split = function(data, K){
  N =data %>% dim() %>% .[1]
  fold_n = round(N/ K)
  remainder = N - (K-1) * fold_n
  block_id = rep(1:(K-1), each= fold_n)
  block_id = c(block_id, rep(K, remainder))
  data['idx'] = 1:(dim(data)[1])
  data = data %>% arrange(X, Y)
  data['block']= block_id
  
  idx = vector(mode = 'list',length = K)
  for (i in 1:K){
    idx[[i]] = data %>% filter(block==i) %>% pull(idx) 
  }
  return(idx)
}

Kmeans_block_split = function(data, K){
  idx = vector(mode = 'list',length = K)
  res = kmeans(data %>%  dplyr::select(Y,X) ,K)
  for (i in 1:K){
    idx[[i]] = which(res$cluster == i)
  }
  return (idx)
}


create_split = function(data, split_func, filter_unlabeled=T){
  idx = split_func(data,3)
  
  for (i in 1:3){
    data[idx[[i]],'block']=i
  }
  
  unique_blocks = data %>% distinct(image, block)
  block_n = unique_blocks %>% dim() %>% .[1]
  val_test_samples = sample(1:block_n, 2)
  
  val_img_block = unique_blocks[val_test_samples[1], ]
  test_img_block = unique_blocks[val_test_samples[2], ]
  
  val = data %>% filter(image==val_img_block$image & block==val_img_block$block)
  test = data %>% filter(image==test_img_block$image & block==test_img_block$block)
  train = data %>% setdiff(val) %>% setdiff(test)
  
  if (filter_unlabeled){
    val = val%>% filter(Label!=0) %>% dplyr::select(-block)
    test = test%>% filter(Label!=0) %>% dplyr::select(-block)
    train = train%>% filter(Label!=0) %>% dplyr::select(-block)
  }
  return(list(val = val,
              test = test,
              train = train))
  
}

set.seed(12344)

kmeans_split = create_split(full_img, Kmeans_block_split, filter_unlabeled=T)
bk_split = create_split(full_img, block_split, filter_unlabeled=T)

CVmaster = function(tidymodel, train_features, training_labels, K, metrics, split_func,
                    .scale=T, .tune_grid=NULL, excld_cols = c('X', 'Y', 'image', 'Label')){
  
  # --------------- Create Formula ---------------
  excld_cols = train_features %>% colnames() %>% intersect(excld_cols)
  feature_names = train_features %>% dplyr::select(-excld_cols) %>% colnames()
  formula = as.formula(paste0('Label ~ ', paste(feature_names, collapse = ' + '))) 
  
  # ensure label is factor
  training_labels = training_labels %>% as.factor()
  
  # full train data with labels
  full_train = train_features %>% dplyr::select(feature_names) %>% mutate(Label=training_labels)
  
  # --------------- Create Recipe ---------------
  model_recipe = recipe(formula, data = full_train)
    if (.scale){
      model_recipe = model_recipe %>% step_normalize(all_numeric_predictors())
    }

  # --------------- Create Resampler ---------------
  cv_splits = split_func(train_features, K=K)
  cv_settings = list(v = K, strata = FALSE, repeats = 1)
  resample_split = list()
  fold_id = paste('Fold ', 1:K)
  N = dim(train_features)[1] 
  
  for (k in 1:K){
    val_idx = cv_splits[[k]]
    train_idx = seq(1, N)[-val_idx]
    resample_split[[k]] = make_splits(list(analysis=train_idx, assessment=val_idx), data=full_train)
  }
  resample_settings = new_rset(splits = resample_split,
                                ids = fold_id,
                                subclass = c("vfold_cv", "rset"),
                                attrib = cv_settings)
  
  # --------------- Create Workflow & Fit CV---------------
  if (!is.null(.tune_grid)){
    res = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(tidymodel) %>%
    tune_grid(
      resample_settings,
      grid=.tune_grid,
      control=control_grid(verbose=T),
      metrics=metrics
    )
  }else{
    res = workflow() %>%
    add_recipe(model_recipe) %>%
    add_model(tidymodel) %>%
    fit_resamples(resamples = resample_settings, metrics = metrics)
  }

  # --------------- Extract CV Loss---------------
  fold_loss = data.frame()
  for (i in 1:K){
    fold_loss = rbind(fold_loss, res$.metrics[[i]])
  }
  # If there is tuning parameters, select the best one. If there are multiple metrics, the first one is used to select.
  if (!is.null(.tune_grid)){
    fold_loss = fold_loss %>% dplyr::filter(.config %in% (res%>%select_best(metric = "roc_auc")%>%pull(.config)))
  }
  
  N_loss =  fold_loss %>% distinct(.metric)%>%pull()%>%length()
  fold_loss = fold_loss %>% dplyr::select(-c(.config, .estimator)) %>%
    mutate(fold = rep(1:K, each=N_loss)) %>%
    pivot_wider(names_from = .metric, values_from = .estimate)
  
  output = list(fold_loss = fold_loss, 
                avg = (fold_loss %>%  dplyr::select(-fold) %>% colMeans()),
                workflow=res)
}

## ---------------------------- Set up Models -------------------------------------
lr_model = logistic_reg() %>% set_engine('glm')

lda_model = discrim_linear() %>% set_engine('MASS')

qda_model = discrim_quad() %>% set_engine('MASS')

rf_model = rand_forest(mode='classification', mtry=tune(), trees=1000, min_n = tune()) %>% 
  set_engine("ranger", num.threads=24)

NB_model = naive_Bayes(smoothness = 1.48, Laplace = 1.08)%>%set_mode('classification')

xgboost_model = boost_tree(tree_depth = tune(), trees = 1000, learn_rate = tune(), min_n = tune(), loss_reduction = tune(), sample_size = tune(), stop_iter = tune())%>%set_engine('xgboost', num.threads=24) %>%set_mode('classification')



## ---------------------------- K-means split -------------------------------------
train_data = rbind(kmeans_split$train, kmeans_split$val) %>% mutate(Label = factor(Label))
lr_res = CVmaster(lr_model,
                  train_features = train_data,
                  training_labels = train_data$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
write_rds(lr_res, file='data/Kmeans_lr_res.rds')


lda_res = CVmaster(lda_model,
                  train_features = train_data,
                  training_labels = train_data$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
write_rds(lda_res, file='data/Kmeans_lda_res.rds')

qda_res = CVmaster(qda_model,
                  train_features = train_data,
                  training_labels = train_data$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
write_rds(qda_res, file='data/Kmeans_qda_res.rds')

rf_res = CVmaster(rf_model,
                  train_features = train_data,
                  training_labels = train_data$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc), .tune_grid = 10)
write_rds(rf_res, file='data/Kmeans_rf_res.rds')

nb_res = CVmaster(NB_model,
                  train_features = train_data,
                  training_labels = train_data$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
 write_rds(nb_res, file='data/Kmeans_nb_res.rds')

xgboost_res = CVmaster(xgboost_model,
                   train_features = train_data,
                   training_labels = train_data$Label,
                   K = 5,
                   split_func = Kmeans_block_split,
                   metrics = metric_set(accuracy, roc_auc), .tune_grid = 10)
 write_rds(xgboost_res, file='data/Kmeans_xgboost_res.rds')

## ---------------------------- Block split -------------------------------------

train_data2 = rbind(bk_split$train, bk_split$val) %>% mutate(Label = factor(Label))
 
lr_res = CVmaster(lr_model,
                  train_features = train_data2,
                  training_labels = train_data2$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
write_rds(lr_res, file='data/Block_lr_res.rds')

lda_res = CVmaster(lda_model,
                  train_features = train_data2,
                  training_labels = train_data2$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
write_rds(lda_res, file='data/Block_lda_res.rds')

qda_res = CVmaster(qda_model,
                  train_features = train_data2,
                  training_labels = train_data2$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc))
write_rds(qda_res, file='data/Block_qda_res.rds')

rf_res = CVmaster(rf_model,
                  train_features = train_data2,
                  training_labels = train_data2$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc), .tune_grid = 10)
write_rds(rf_res, file='data/Block_rf_res.rds')

nb_res = CVmaster(NB_model,
                  train_features = train_data2,
                  training_labels = train_data2$Label,
                  K = 5,
                  split_func = Kmeans_block_split,
                  metrics = metric_set(accuracy, roc_auc), .tune_grid = 10)
 write_rds(nb_res, file='data/Block_nb_res.rds')

xgboost_res = CVmaster(xgboost_model,
                   train_features = train_data2,
                   training_labels = train_data2$Label,
                   K = 5,
                   split_func = Kmeans_block_split,
                   metrics = metric_set(accuracy, roc_auc), .tune_grid = 10)
 write_rds(xgboost_res, file='data/Block_xgboost_res.rds')



```
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
